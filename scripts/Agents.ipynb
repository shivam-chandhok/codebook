{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99eb3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import httpx\n",
    "import os\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \" \"\n",
    "assert \"OPENAI_API_KEY\" in os.environ\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b59cf1",
   "metadata": {},
   "source": [
    "# Agent from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e555642",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, input_prompt=\"\"):\n",
    "        self.input_prompt = input_prompt ## prompt to LLM to explain task to perform\n",
    "        self.messages = [] ## cache of messages to keep track\n",
    "        if self.input_prompt:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": input_prompt})\n",
    "\n",
    "    def __call__(self, message): ## user message/question\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "                        model=\"gpt-4o\", \n",
    "                        temperature=0,\n",
    "                        messages=self.messages)\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7031bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "average_dog_weight:\n",
    "e.g. average_dog_weight: Collie\n",
    "returns average weight of a dog when given the breed\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: How much does a Bulldog weigh?\n",
    "Thought: I should look the dogs weight using average_dog_weight\n",
    "Action: average_dog_weight: Bulldog\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: A Bulldog weights 51 lbs\n",
    "\n",
    "You then output:\n",
    "\n",
    "Answer: A bulldog weights 51 lbs\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3186454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(what):\n",
    "    return eval(what)\n",
    "\n",
    "def average_dog_weight(name):\n",
    "    if name in \"Scottish Terrier\": \n",
    "        return(\"Scottish Terriers average 20 lbs\")\n",
    "    elif name in \"Border Collie\":\n",
    "        return(\"a Border Collies average weight is 37 lbs\")\n",
    "    elif name in \"Toy Poodle\":\n",
    "        return(\"a toy poodles average weight is 7 lbs\")\n",
    "    else:\n",
    "        return(\"An average dog weights 50 lbs\")\n",
    "\n",
    "known_actions = {\n",
    "    \"calculate\": calculate,\n",
    "    \"average_dog_weight\": average_dog_weight\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50773b32",
   "metadata": {},
   "source": [
    "## One Agent Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "070af8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I should look up the average weight of a toy poodle using the average_dog_weight function.\n",
      "Action: average_dog_weight: Toy Poodle\n",
      "PAUSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\naverage_dog_weight:\\ne.g. average_dog_weight: Collie\\nreturns average weight of a dog when given the breed\\n\\nExample session:\\n\\nQuestion: How much does a Bulldog weigh?\\nThought: I should look the dogs weight using average_dog_weight\\nAction: average_dog_weight: Bulldog\\nPAUSE\\n\\nYou will be called again with this:\\n\\nObservation: A Bulldog weights 51 lbs\\n\\nYou then output:\\n\\nAnswer: A bulldog weights 51 lbs'},\n",
       " {'role': 'user', 'content': 'How much does a toy poodle weigh?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Thought: I should look up the average weight of a toy poodle using the average_dog_weight function.\\nAction: average_dog_weight: Toy Poodle\\nPAUSE'},\n",
       " {'role': 'user',\n",
       "  'content': 'Observation: a toy poodles average weight is 7 lbs'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Answer: A toy poodle weighs an average of 7 lbs.'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot = Agent(prompt)\n",
    "\n",
    "### manually running one iteration\n",
    "result = abot(\"How much does a toy poodle weigh?\") ## ask question\n",
    "print(result) ## output suggests to take an action average_dog_weight(Toy Poodle)\n",
    "\n",
    "result = average_dog_weight(\"Toy Poodle\") ## take the action\n",
    "next_prompt = \"Observation: {}\".format(result) ## make an Observation -> with result of action\n",
    "abot(next_prompt) ## call llm with the observation\n",
    "abot.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e14ff467",
   "metadata": {},
   "outputs": [],
   "source": [
    "abot = Agent(prompt)\n",
    "\n",
    "### manually running one iteration\n",
    "def agent_iteration(abot, question):\n",
    "    result = abot(question) ## ask question\n",
    "    print(result) ## Get Thought and potential Action llm thinks we should run\n",
    "    \n",
    "    ## find actions from output string using regex\n",
    "    action_re = re.compile('^Action: (\\w+): (.*)$')\n",
    "    actions = [\n",
    "            action_re.match(a) \n",
    "            for a in result.split('\\n') \n",
    "            if action_re.match(a)\n",
    "        ]\n",
    "    print(actions)\n",
    "    action, action_input = actions[0].groups()\n",
    "    print(action, action_input)\n",
    "    \n",
    "    ##execute action\n",
    "    observation = known_actions[action](action_input)\n",
    "    print(\"Observation:\", observation)\n",
    "    next_prompt = \"Observation: {}\".format(observation)\n",
    "    result = abot(next_prompt) ## call llm with the observation\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c5f2889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to look up the average weight of a Toy Poodle using the average_dog_weight action.\n",
      "Action: average_dog_weight: Toy Poodle\n",
      "PAUSE\n",
      "[<re.Match object; span=(0, 38), match='Action: average_dog_weight: Toy Poodle'>]\n",
      "average_dog_weight Toy Poodle\n",
      "Observation: a toy poodles average weight is 7 lbs\n",
      "Answer: A Toy Poodle weighs an average of 7 lbs.\n"
     ]
    }
   ],
   "source": [
    "question = \"How much does a toy poodle weigh?\"\n",
    "agent_iteration(abot, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b49a9c3",
   "metadata": {},
   "source": [
    "## Loop for continuous Agents to solve tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c5e3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### copy agent iteration fn built above\n",
    "def agent_iteration(abot, question):\n",
    "    result = abot(question) ## ask question\n",
    "    print(result)\n",
    "    action_re = re.compile('^Action: (\\w+): (.*)$')\n",
    "    actions = [\n",
    "            action_re.match(a) \n",
    "            for a in result.split('\\n') \n",
    "            if action_re.match(a)]\n",
    "    if actions:\n",
    "        action, action_input = actions[0].groups()\n",
    "        observation = known_actions[action](action_input)\n",
    "        print(\"Observation:\", observation)\n",
    "        next_prompt = \"Observation: {}\".format(observation)\n",
    "        return next_prompt\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Continuous agent\n",
    "\n",
    "def query(question, max_turns=5):\n",
    "    i = 0\n",
    "    bot = Agent(prompt)\n",
    "    next_prompt = question\n",
    "    while i < max_turns:\n",
    "        i += 1\n",
    "        next_prompt = agent_iteration(abot, next_prompt)\n",
    "        if next_prompt is None: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d43aaf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I already have the average weight of a Border Collie, which is 37 lbs. Now I need to find the average weight of a Scottish Terrier to calculate their combined weight.\n",
      "Action: average_dog_weight: Scottish Terrier\n",
      "PAUSE\n",
      "Observation: Scottish Terriers average 20 lbs\n",
      "Thought: I now have the average weights of both a Border Collie (37 lbs) and a Scottish Terrier (20 lbs). I need to add these weights together to find their combined weight.\n",
      "Action: calculate: 37 + 20\n",
      "PAUSE\n",
      "Observation: 57\n",
      "Answer: The combined weight of a Border Collie and a Scottish Terrier is 57 lbs.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"I have 2 dogs, a border collie and a scottish terrier. \\\n",
    "What is their combined weight\"\"\"\n",
    "query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f920f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n",
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "## LangGraph\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=4) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b994dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LangGraph imports\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "tool = TavilySearchResults(max_results=4) #increased number of results\n",
    "print(type(tool))\n",
    "print(tool.name)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, input_prompt=\"\"):\n",
    "        self.system = input_prompt\n",
    "        \n",
    "        #### BUILD GRAPH #######\n",
    "        graph = StateGraph(AgentState) ## initialize state of agent\n",
    "        graph.add_node(\"llm\", self.call_openai) ## add llm node which calls function 'call_openai'\n",
    "        graph.add_node(\"action\", self.take_action) ## add action node which calls function 'take_action'\n",
    "        graph.add_conditional_edges(\"llm\", ## add conditional edge, first argument is node where edge starts i.e \"llm\"\n",
    "        self.exists_action, ## function to call to understand what to do next\n",
    "            {True: \"action\", False: END} ## if function returns True, take the action other wise end\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:openeqa]",
   "language": "python",
   "name": "conda-env-openeqa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
